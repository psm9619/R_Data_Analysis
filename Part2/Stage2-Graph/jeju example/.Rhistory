readLines("응답소_2015_07.txt"),
readLines("응답소_2015_08.txt"),
readLines("응답소_2015_09.txt"),
readLines("응답소_2015_10.txt"),
readLines("응답소_2015_11.txt"),
readLines("응답소_2015_12.txt"))
total <- sapply(tot, extractNoun, USE.NAMES = F)
total <- unlist(total)
total <- str_replace_all(total, "[:alpha:]","")
t_gsub <- readLines("응답소gsub.txt")
re_subtxt <- c("t_gsub", "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","박원순\\S*","서울시\\S*","시장\\S*","을\\S*",
"까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*"
"아니\\S*", "랑\\S*", "안녕\\S*", "입니다", "생각", "는\\S*")
for (i in 1:length(re_subtxt)) {
total <- gsub(re_subtxt[i], "", total)
}  # for loops doesn't work very well.. so did some more hands-on work
total <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, total)
write(unlist(total), "tot15_rev.txt")
revT <- read.table("tot15_rev.txt")
nrow(revT)
countT <- table(revT)
palete <- brewer.pal(9, "Set1")
re_subtxt <- c("t_gsub", "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","박원순\\S*","서울시\\S*","시장\\S*","을\\S*",
"까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*",
"아니\\S*", "랑\\S*", "안녕\\S*", "입니다", "생각", "는\\S*")
for (i in 1:length(re_subtxt)) {
total <- gsub(re_subtxt[i], "", total)
}  # for loops doesn't work very well.. so did some more hands-on work
total <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, total)
write(unlist(total), "tot15_rev.txt")
revT <- read.table("tot15_rev.txt")
tot <- c(readLines("응답소_2015_01.txt"),
readLines("응답소_2015_02.txt"),
readLines("응답소_2015_03.txt"),
readLines("응답소_2015_04.txt"),
readLines("응답소_2015_05.txt"),
readLines("응답소_2015_06.txt"),
readLines("응답소_2015_07.txt"),
readLines("응답소_2015_08.txt"),
readLines("응답소_2015_09.txt"),
readLines("응답소_2015_10.txt"),
readLines("응답소_2015_11.txt"),
readLines("응답소_2015_12.txt"))
total <- sapply(tot, extractNoun, USE.NAMES = F)
total <- unlist(total)
total <- str_replace_all(total, "[:alpha:]","")
t_gsub <- readLines("응답소gsub.txt")
re_subtxt <- c("t_gsub", "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","박원순\\S*","서울시\\S*","시장\\S*","을\\S*",
"까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*",
"아니\\S*", "랑\\S*", "안녕\\S*", "입니다", "생각", "는\\S*")
for (i in 1:length(re_subtxt)) {
total <- gsub(re_subtxt[i], "", total)
}  # for loops doesn't work very well.. so did some more hands-on work
total <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, total)
write(unlist(total), "tot15_rev.txt")
revT <- read.table("tot15_rev.txt")
nrow(revT)
countT <- table(revT)
palete <- brewer.pal(9, "Set1")
par(bg="black")
wordcloud(names(countT), freq = countT, scale = c(7,0.5),
rot.per=0.85, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
total <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, total)
write(unlist(total), "tot15_rev.txt")
revT <- read.table("tot15_rev.txt")
nrow(revT)
countT <- table(revT)
palete <- brewer.pal(10, "Set3")
par(bg="black")
wordcloud(names(countT), freq = countT, scale = c(4,0.5),
rot.per=0.25, min.freq=10, max.words=100,
random.order=F, random.color=T, colors=palete)
wordcloud(names(countT), freq = countT, scale = c(4,0.5),
rot.per=0.25, min.freq=10, max.words=50,
random.order=F, random.color=T, colors=palete)
head(freq1, 20)
setwd("D:/Workspace/R_data_analysis/Part2/Stage1-WordCloud/ex4. SteveJobs")
data1 <- readLines("steve.txt")
data1
class(data1)
corp1 <- Corpus (VectorSource(data1))
corp1
inspect(corp1)
tdm <- TermDocumentMatrix(corp1)
tdm
m <- as.matrix(tdm)
m
corp2 <- tm_map(corp1, stripWhitespace)
corp2 <- tm_map(corp2, tolower)
corp2 <- tm_map(corp2, removeNumbers)
corp2 <- tm_map(corp2, removePunctuation)
#corp2 <- tm_map(corp2, PlainTextDocument)
#swords <- c(stopwords('en'), 'and', 'but', 'not'); swords
corp2 <- tm_map(corp2, removeWords, stopwords('en')) ; corp2
tdm2 <- TermDocumentMatrix(corp2)
tdm2
m2 <- as.matrix(tdm2)
colnames(m2) <- seq(10,40,10)
freq1 <- sort(rowSums(m2), decreasing=T)
head(freq1, 20)
freq2 <- sort(colSums())
head(freq2, 20)
colnames(m2) <- seq(10,590,10)
freq1 <- sort(rowSums(m2), decreasing=T)
head(freq1, 20)
freq2 <- sort(colSums(m2), decreasing=T)
head(freq2, 20)
findFreqTerms(tdm2, 2)
wordcloud(names(freq1), freq = freq1, scale = c(4,0.5),
rot.per=0.25, min.freq=10, max.words=50,
random.order=F, random.color=T, colors=palete)
palete <- brewer.pal (7,"Set3")
par(bg="black")
wordcloud(names(freq1), freq = freq1, scale = c(5,0.3),
rot.per=0.25, min.freq=1,
random.order=F, random.color=T, colors=palete)
total[299:399]
total
tot <- c(readLines("응답소_2015_01.txt"),
readLines("응답소_2015_02.txt"),
readLines("응답소_2015_03.txt"),
readLines("응답소_2015_04.txt"),
readLines("응답소_2015_05.txt"),
readLines("응답소_2015_06.txt"),
readLines("응답소_2015_07.txt"),
readLines("응답소_2015_08.txt"),
readLines("응답소_2015_09.txt"),
readLines("응답소_2015_10.txt"),
readLines("응답소_2015_11.txt"),
readLines("응답소_2015_12.txt"))
total <- sapply(tot, extractNoun, USE.NAMES = F)
total <- unlist(total)
total[299:399]
setwd("D:/Workspace/R_data_analysis/Part2/WordCloud_Practice")
library(dplyr)
library(KoNLP)
library(wordcloud)
library(stringr)
library(RColorBrewer)
useSejongDic()
tot <- c(readLines("응답소_2015_01.txt"),
readLines("응답소_2015_02.txt"),
readLines("응답소_2015_03.txt"),
readLines("응답소_2015_04.txt"),
readLines("응답소_2015_05.txt"),
readLines("응답소_2015_06.txt"),
readLines("응답소_2015_07.txt"),
readLines("응답소_2015_08.txt"),
readLines("응답소_2015_09.txt"),
readLines("응답소_2015_10.txt"),
readLines("응답소_2015_11.txt"),
readLines("응답소_2015_12.txt"))
total <- sapply(tot, extractNoun, USE.NAMES = F)
total <- unlist(total)
total[299:399]
total <- str_replace_all(total, "[:alpha:]","")
total[299:399]
total <- str_replace_all(total, "[^[:alpha:]","")
tot <- c(readLines("응답소_2015_01.txt"),
readLines("응답소_2015_02.txt"),
readLines("응답소_2015_03.txt"),
readLines("응답소_2015_04.txt"),
readLines("응답소_2015_05.txt"),
readLines("응답소_2015_06.txt"),
readLines("응답소_2015_07.txt"),
readLines("응답소_2015_08.txt"),
readLines("응답소_2015_09.txt"),
readLines("응답소_2015_10.txt"),
readLines("응답소_2015_11.txt"),
readLines("응답소_2015_12.txt"))
total <- sapply(tot, extractNoun, USE.NAMES = F)
total <- unlist(total)
total[299:399]
total <- str_replace_all(total, "[^:alpha:]]","")
total[299:399]
source('D:/Workspace/R_data_analysis/Part2/WordCloud_Practice/2015total.R', encoding = 'UTF-8', echo=TRUE)
library(dplyr)
library(KoNLP)
library(wordcloud)
library(stringr)
library(RColorBrewer)
useSejongDic()
tot <- c(readLines("응답소_2015_01.txt"),
readLines("응답소_2015_02.txt"),
readLines("응답소_2015_03.txt"),
readLines("응답소_2015_04.txt"),
readLines("응답소_2015_05.txt"),
readLines("응답소_2015_06.txt"),
readLines("응답소_2015_07.txt"),
readLines("응답소_2015_08.txt"),
readLines("응답소_2015_09.txt"),
readLines("응답소_2015_10.txt"),
readLines("응답소_2015_11.txt"),
readLines("응답소_2015_12.txt"))
total <- sapply(tot, extractNoun, USE.NAMES = F)
total <- unlist(total)
total[299:399]
total <- str_replace_all(total, "[^:alpha:]]","")
total[299:399]
t_gsub <- readLines("응답소gsub.txt")
t_gsub <- readLines("응답소gsub.txt")
re_subtxt <- c(t_gsub, "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","씨\\S*","서울시\\S*","시장\\S*","을\\S*","까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*","를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*","아니\\S*", "랑\\S*", "안녕\\S*", "입니다", "생각", "는\\S*", "서울\\S*", "seo\\S*" , "나라\\S*", "민원\\S*", "백사마\\S*", "존경\\S*", "없\\S*", "제발\\S*", "께\\S*","진짜\\S*", "저희\\S*", "와\\S*", "전국\\S*", "이런\\S*", "응답소\\S*", "더이상\\S*", "당분간\\S*","동성애\\S*", "퀴어\\S*", "게이\\S*")
write (re_subtxt, "resub.txt")
resub <- readLines("resub.txt")
for (i in 1:length(resub)) {
if (resub[i] %in% c("동성애\\S*", "퀴어\\S*", "게이\\S*"))
gsub(resub[i], "퀴어", total)
else {
total <- gsub(resub[i], "", total)
}  # for loops doesn't work very well.. so did some more hands-on work
}
total <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, total)
write(unlist(total), "tot15_rev.txt")
revT <- read.table("tot15_rev.txt")
nrow(revT)
countT <- table(revT)
palete <- brewer.pal(10, "Set3")
par(bg="black")
wordcloud(names(countT), freq = countT, scale = c(4,0.5),
rot.per=0.35, min.freq=10, max.words=100,
random.order=F, random.color=T, colors=palete)
tot <- c(readLines("응답소_2015_01.txt"),
readLines("응답소_2015_02.txt"),
readLines("응답소_2015_03.txt"),
readLines("응답소_2015_04.txt"),
readLines("응답소_2015_05.txt"),
readLines("응답소_2015_06.txt"),
readLines("응답소_2015_07.txt"),
readLines("응답소_2015_08.txt"),
readLines("응답소_2015_09.txt"),
readLines("응답소_2015_10.txt"),
readLines("응답소_2015_11.txt"),
readLines("응답소_2015_12.txt"))
total <- sapply(tot, extractNoun, USE.NAMES = F)
total <- unlist(total)
total <- str_replace_all(total, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
t_gsub <- readLines("응답소gsub.txt")
re_subtxt <- c(t_gsub, "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","씨\\S*","서울시\\S*","시장\\S*","을\\S*","까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*","를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*","아니\\S*", "랑\\S*", "안녕\\S*", "입니다", "생각", "는\\S*", "서울\\S*", "seo\\S*" , "나라\\S*", "민원\\S*", "백사마\\S*", "존경\\S*", "없\\S*", "제발\\S*", "께\\S*","진짜\\S*", "저희\\S*", "와\\S*", "전국\\S*", "이런\\S*", "응답소\\S*", "더이상\\S*", "당분간\\S*")
write (re_subtxt, "resub.txt")
resub <- readLines("resub.txt")
for (i in 1:length(resub)) {
total <- gsub(resub[i], "", total)
}
total <- gsub ("동성애\\S*", "퀴어", total)
total <- gsub ("퀴어\\S*", "퀴어", total)
total <- gusb ("게이\\S*", "퀴어", total)
total <- gsub ("게이\\S*", "퀴어", total)
total <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, total)
write(unlist(total), "tot15_rev.txt")
revT <- read.table("tot15_rev.txt")
nrow(revT)
countT <- table(revT)
palete <- brewer.pal(10, "Set3")
par(bg="black")
wordcloud(names(countT), freq = countT, scale = c(4,0.5),
rot.per=0.35, min.freq=10, max.words=100,
random.order=F, random.color=T, colors=palete)
alert <- readLines ("oracle_alert.txt")
knitr::opts_chunk$set(echo = TRUE)
re_subtxt <- c(t_gsub, "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","씨\\S*","서울시\\S*","시장\\S*","을\\S*","까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*","를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*","아니\\S*", "랑\\S*", "안녕\\S*", "입니다", "생각", "는\\S*", "서울\\S*", "seo\\S*" , "나라\\S*", "민원\\S*", "백사마\\S*", "존경\\S*", "없\\S*", "제발\\S*", "께\\S*","진짜\\S*", "저희\\S*", "와\\S*", "전국\\S*", "이런\\S*", "응답소\\S*", "더이상\\S*", "당분간\\S*", "우리\\S*", "들이\\S*", "민국\\S*")
setwd("D:/Workspace/R_data_analysis/Part2/Stage1-WordCloud/new")
library(KoNLP)
library(wordcloud)
alert <- readLines ("oracle_alert_testdb.txt")
haed(alert,10)
alert <- readLines ("oracle_alert_testdb.txt")
setwd("D:/Workspace/R_data_analysis/Part2/Stage1-WordCloud/new")
alert <- readLines ("oracle_alert_testdb.txt")
alert <- readLines ("oracle_alert_testdb.log")
head(alert,10)
error_1 <- gsub(" ", "_", alert)
head(unlist(error_1), 29)
head(unlist(error_1), 20)
error_2 <- unlist(error_1)
error_2 <- Filter(function(x), {nchar(x) >= 5}, error_2)
head(error_2, 10)
error_3 <- grep ("^ORA-+", error_2, value=T)
head(unlist(error_3), 20)
write(unlist(error_3), "alert_testdb2.log")
rev <- read.table("alert_testdb2.log")
nrow(rev)
errorcount <- table (rev)
head(sort(errorcount, decreasing=T), 20)
head(sort(errorcount, decreasing=T), 20)
palete <- brewer.pal(10, "Set3")
par(bg="black")
wordcloud(names(errorcount), freq = errorcount, scale = c(4,0.5),
rot.per=0.35, min.freq=10, max.words=100,
random.order=F, random.color=T, colors=palete)
wordcloud(names(errorcount), freq = errorcount, scale = c(4,0.5),
rot.per=0.15, min.freq=10, max.words=100,
random.order=F, random.color=T, colors=palete)
wordcloud(names(errorcount), freq = errorcount, scale = c(4,0.5),
rot.per=0.15, min.freq=1,
random.order=F, random.color=T, colors=palete)
legend(0.3,1, "Oracle Alert Log File 분석", cex=0.8, fill=NA, text.col="red", bg="transparent", text.font=2, box.col="grey")
t_gsub <- readLines("응답소gsub.txt")
setwd("D:/Workspace/R_data_analysis/Part2/Stage2-Graph/jeju example")
library (KoNLP)
library(wordcloud)
useSejongDic()
library(stringr)
mergeUserDic(data.frame   #mergeUserDic (data.frame(readLines())) 는 deprecated, 앞으로는 가급적 buidDictionary()를 쓰라고 R 에서 요청
(readLines("제주도여행지.txt"),"ncn")) # 텍스트 파일에 있는 여행지들을 통째로 딕션에 더한 것
txt <- readLines("jeju.txt") # 1차
place <- sapply(txt, extractNoun, USE.NAMES = F) # 2차
cdata <- unlist(place)  #3차
place2 <- str_replace_all(cdata, "[^:alpha:]]", "") #한글, 영어 제외 다른 데이터를 모두 "" 로 replace 하는 것
place2 <- gsub(" ", "", place2)
place2 <- gsub ("\\d+", "", place2)  #원래는 위에 str_replace_all 에서 [^:alpha:]] 가 잘 되면 숫자도 다 없어지는게 정상인데 안 없어짐
txt_gsub <- readLines("제주도여행코스gsub.txt")
for (i in 1:length(txt_gsub)) {
place2<- gsub(txt_gsub[i], "", place2)
} ; place2
place2 <- Filter(function(x) {nchar(x) >= 2}, place2)  #2글자 이상만 추출함
write(unlist(place2), "jeju_revised.txt")
revised <- read.table("jeju_revised.txt")
nrow(revised)
wordcount <- table(revised)
head(sort(wordcount, decreasing=T), 30)
top10 <- head(sort(wordcount, decreasing=T), 10)
pie (top10, main= "제주도 추천 여행코스 Top 10")
pie (top10, col= rainbow(10), main= "제주도 추천 여행코스 Top 10")
pie (top10, col= rainbow(10), radius=1, main= "제주도 추천 여행코스 Top 10")
pie (top10, col= rainbow(10), radius=1, main= "제주도 추천 여행코스 Top 10")
pie (top10, col= rainbow(10), radius=2, main= "제주도 추천 여행코스 Top 10")
pie (top10, col= rainbow(10), radius=1, main= "제주도 추천 여행코스 Top 10")
pie (top10, col= pal, radius=1, main= "제주도 추천 여행코스 Top 10")
pal <- brewer.pal(10,"Blues")
top10 <- head(sort(wordcount, decreasing=T), 10)
pie (top10, col= pal, radius=1, main= "제주도 추천 여행코스 Top 10")
pal <- brewer.pal(10,"YlOrRd")
top10 <- head(sort(wordcount, decreasing=T), 10)
pie (top10, col= pal, radius=1, main= "제주도 추천 여행코스 Top 10")
par(bg="black")
top10 <- head(sort(wordcount, decreasing=T), 10)
pie (top10, col= pal, radius=1, main= "제주도 추천 여행코스 Top 10")
par(bg="blue")
top10 <- head(sort(wordcount, decreasing=T), 10)
pie (top10, col= pal, radius=1, main= "제주도 추천 여행코스 Top 10")
pal <- brewer.pal(10,"YlOrRd")
pal <- brewer.pal(10, "Blues")
top10 <- head(sort(wordcount, decreasing=T), 10)
pie (top10, col= rainbow(10), radius=1, main= "제주도 추천 여행코스 Top 10")
par(bg = "white")
top10 <- head(sort(wordcount, decreasing=T), 10)
pie (top10, col= pal, radius=1, main= "제주도 추천 여행코스 Top 10")
pie (top10, col= pal, radius=1, main= "제주도 추천 여행코스 Top 10",
+ cex = 0.8, labels = lab)
pie (top10, col= pal, radius=1, main= "제주도 추천 여행코스 Top 10",
cex = 0.8, labels = lab)
lab <- paste(names(top10), "\n", pct, "%")
top10 <- head(sort(wordcount, decreasing=T), 10)
pie (top10, col= pal, radius=1, main= "제주도 추천 여행코스 Top 10",
cex = 0.8, labels = lab)
lab <- paste(names(top10), "\n", pct, "%", sep='')
pct <- round(top10/sum(top10) * 100, 1)
lab <- paste(names(top10), "\n", pct, "%", sep='')
top10 <- head(sort(wordcount, decreasing=T), 10)
pie (top10, col= pal, radius=1, main= "제주도 추천 여행코스 Top 10",
cex = 0.8, labels = lab)
library(ggplot2)
str(top10)
df_top10 <- as.data.frame(top10)
ggplot (df_top10, aes(x='', y=Freq, fill = rev)) +
geom_bar(width=1, stat='identity')
library(ggplot2)
###  regraphing using ggplot
str(top10) #current top10 is a Table. We need Data frame to use ggplot
df_top10 <- as.data.frame(top10)
ggplot (df_top10, aes(x='', y=Freq, fill = rev)) +
geom_bar(width=1, stat='identity')
df_top10
ggplot (df_top10, aes(x='', y=Freq, fill = rev)) +
geom_bar(width=1, stat='identity')
# 검색어 빈도 결과를 그래프로 표시하기
# 예제 1-3 제주도 추천 여행지
library (KoNLP)
library(wordcloud)
useSejongDic()
library(stringr)
library(ggplot2)
mergeUserDic(data.frame   #mergeUserDic (data.frame(readLines())) 는 deprecated, 앞으로는 가급적 buidDictionary()를 쓰라고 R 에서 요청
(readLines("제주도여행지.txt"),"ncn")) # 텍스트 파일에 있는 여행지들을 통째로 딕션에 더한 것
txt <- readLines("jeju.txt") # 1차
place <- sapply(txt, extractNoun, USE.NAMES = F) # 2차
cdata <- unlist(place)  #3차
place2 <- str_replace_all(cdata, "[^:alpha:]]", "") #한글, 영어 제외 다른 데이터를 모두 "" 로 replace 하는 것
place2 <- gsub(" ", "", place2)
place2 <- gsub ("\\d+", "", place2)  #원래는 위에 str_replace_all 에서 [^:alpha:]] 가 잘 되면 숫자도 다 없어지는게 정상인데 안 없어짐
txt_gsub <- readLines("제주도여행코스gsub.txt")
for (i in 1:length(txt_gsub)) {
place2<- gsub(txt_gsub[i], "", place2)
} ; place2
place2 <- Filter(function(x) {nchar(x) >= 2}, place2)  #2글자 이상만 추출함
write(unlist(place2), "jeju_revised.txt")
revised <- read.table("jeju_revised.txt")
nrow(revised)
wordcount <- table(revised)
head(sort(wordcount, decreasing=T), 30)
top10 <- head(sort(wordcount, decreasing=T), 10)
pal <- brewer.pal(10, "Blues")
par(bg = "white")
pct <- round(top10/sum(top10) * 100, 1)
lab <- paste(names(top10), "\n", pct, "%", sep='')
pie (top10, col= pal, radius=1, main= "제주도 추천 여행코스 Top 10",
cex = 0.8, labels = lab)
###  regraphing using ggplot
str(top10) #current top10 is a Table. We need Data frame to use ggplot
df_top10 <- as.data.frame(top10)
df_top10
ggplot (df_top10, aes(x='', y=Freq, fill = rev)) +
geom_bar(width=1, stat='identity')
ggplot (df_top10, aes(x='', y=Freq)) +
geom_bar(width=1, stat='identity')
ggplot (df_top10, aes(x='', y=Freq, fill = rev)) +
geom_bar(width=1, stat='identity')
ggplot (df_top10, aes(x='', y=Freq, fill = revised)) +
geom_bar(width=1, stat='identity')
ggplot (df_top10, aes(x='', y=Freq, fill = revised)) +
geom_bar(width=1, stat='identity') +  #여기까지는 stacked bar graph
coord_polar("y", start=0)
library(dplyr)
df_top10 <- df_top10 %>%
mutate(pct= Freq/sum(Freq) * 100)
df_top10
options(digits = 2)  ### 소수점 이하 두 자리까지만 표기
df_top10 <- as.data.frame(top10)
df_top10 <- df_top10 %>%
mutate(pct= Freq/sum(Freq) * 100)
df_top10
library(dplyr)
options(digits = 2)  ### 소수점 이하 두 자리까지만 표기
df_top10 <- as.data.frame(top10)
df_top10 <- df_top10 %>%
mutate(pct= Freq/sum(Freq) * 100)
df_top10
df_top10 <- df_top10 %>%
mutate(pct= Freq/sum(Freq) * 100) %>%
mutate (ylabel = paste(sprintf("%4.1f", pct), '%', sep = ''))
df_top10
df_top10 <- df_top10 %>%
mutate(pct= Freq/sum(Freq) * 100) %>%
mutate (ylabel = paste(sprintf("%4.1f", pct), '%', sep = '')) +
mutate (ylab2 = paste (pct, '%', sep=''))
df_top10
df_top10 <- df_top10 %>%
mutate(pct= Freq/sum(Freq) * 100) %>%
mutate (ylabel = paste(sprintf("%4.1f", pct), '%', sep = '')) %>%
mutate (ylab2 = paste (pct, '%', sep=''))
df_top10
df_top10 <- df_top10 %>%
mutate(pct= Freq / sum(Freq) * 100) %>%
mutate (ylabel = paste(sprintf("%4.1f", pct), '%', sep = '')) %>%
mutate (ylab2 = paste (pct, '%', sep=''))
df_top10
ggplot (df_top10, aes(x='', y=Freq, fill = revised)) +
geom_bar(width=1, stat='identity') +  #여기까지는 stacked bar graph
coord_polar("y", start=0)  #위에서 만들어진 bar graph 를 polar 로 말으면 자동적으로 만들어짐
df_top10 <- df_top10 %>%
mutate(pct= Freq / sum(Freq) * 100) %>%
mutate (ylabel = paste(sprintf("%4.1f", pct), '%', sep = '')) %>%
mutate (ylab2 = paste (pct, '%', sep='')) %>%
mutate(ypos = cumsum(pct)- 0.5*pct)
df_top10
df_top10 <- df_top10 %>%
mutate(pct= Freq / sum(Freq) * 100) %>%
mutate (ylabel = paste(sprintf("%4.1f", pct), '%', sep = '')) %>%
mutate (ylab2 = paste (pct, '%', sep='')) %>%
arrange(desc(revised)) %>%
mutate(ypos = cumsum(pct)- 0.5*pct)
df_top10
ggplot (df_top10, aes(x='', y=Freq, fill = revised)) +
geom_bar(width=1, stat='identity') +  #여기까지는 stacked bar graph
geom_text(aes(y=ypos, label = ylabel), color = "black")
ggplot (df_top10, aes(x='', y=Freq, fill = revised)) +
geom_bar(width=1, stat='identity') +  #여기까지는 stacked bar graph
geom_text(aes(y=ypos, label = ylabel), color = "black") +
coord_polar("y", start=0)  #위에서 만들어진 bar graph 를 polar 로 말으면 자동적으로 만들어짐
ggplot (df_top10, aes(x='', y=Freq, fill = revised)) +
geom_bar(width=1, stat='identity') +  #여기까지는 stacked bar graph
geom_text(aes(y=ypos, label = ylabel), color = "black")
ggplot (df_top10, aes(x='', y=Freq, fill = revised)) +
geom_bar(width=1, stat='identity') +  #여기까지는 stacked bar graph
geom_text(aes(y=ypos, label = ylabel), color = "black") +
coord_polar("y", start=0)  #위에서 만들어진 bar graph 를 polar 로 말으면 자동적으로 만들어짐
ggplot (df_top10, aes(x='', y=Freq, fill = revised)) +
geom_bar(width=1, stat='identity') +  #여기까지는 stacked bar graph
geom_text(aes(y=ypos, label = ylabel), color = "white") +
coord_polar("y", start=0)  #위에서 만들어진 bar graph 를 polar 로 말으면 자동적으로 만들어짐
ggplot (df_top10, aes(x='', y=Freq, fill = revised)) +
geom_bar(width=1, stat='identity') +  #여기까지는 stacked bar graph
geom_text(aes(y=ypos, label = ylabel), color = "white") +
coord_polar("y", start=0) +  #위에서 만들어진 bar graph 를 polar 로 말으면 자동적으로 만들어짐
ggtitle ("제주도 추천 여행 코스 TOP10") +
geom_text(aes(y=ypos, label=ylabel), color='black')
df_top10 <- as.data.frame(top10)
df_top10 <- df_top10 %>%
mutate(pct= Freq / sum(Freq) * 100) %>%
mutate (ylabel = paste(sprintf("%4.1f", pct), '%', sep = '')) %>%
mutate (ylab2 = paste (pct, '%', sep='')) %>%  # This method is supposed to give non-summarised (2digit 이하가 아닌) percentage
arrange(desc(revised)) %>%
mutate(ypos = cumsum(pct)- 0.5*pct)
df_top10
ggplot (df_top10, aes(x='', y=Freq, fill = revised)) +
geom_bar(width=1, stat='identity') +  #여기까지는 stacked bar graph
geom_text(aes(y=ypos, label = ylabel), color = "white") +
coord_polar("y", start=0) +  #위에서 만들어진 bar graph 를 polar 로 말으면 자동적으로 만들어짐
ggtitle ("제주도 추천 여행 코스 TOP10") +
geom_text(aes(y=ypos, label=ylabel), color='black')
