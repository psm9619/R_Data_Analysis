head(jan, 100)
jan <- gsub("\\^", "", jan)
head(jan, 100)
jan <- gsub("을\\S*", "", jan)
head(jan, 100)
txt <- readLines("응답소_2015_01.txt")
jan <- sapply(txt, extractNoun, USE.NAMES = F)
jan <- unlist(jan) ; jan[1500:2000]
# for some reason, the below order does not remove non-alphabet/한글 data compeletely. After this step, dataset still contains some numbers
jan
jan <- str_replace_all(jan, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
t_gsub
for (i in 1:length(t_gsub)) {
jan <- gsub(t_gsub[i], "", jan)
} ; jan
jan <- gsub("\\W", "", jan)
head(jan, 100)
txt <- readLines("응답소_2015_01.txt")
jan <- sapply(txt, extractNoun, USE.NAMES = F)
jan <- unlist(jan) ; jan[1500:2000]
# for some reason, the below order does not remove non-alphabet/한글 data compeletely. After this step, dataset still contains some numbers
jan
jan <- str_replace_all(jan, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
t_gsub
for (i in 1:length(t_gsub)) {
jan <- gsub(t_gsub[i], "", jan)
} ; head(jan, 100)
for (i in 1:length(t_gsub)) {
jan <- gsub(t_gsub[i], "", jan)
} ; head(jan, 400)
jan <- gsub("\\W", "", jan)
head(jan, 400)
txt <- readLines("응답소_2015_01.txt")
jan <- sapply(txt, extractNoun, USE.NAMES = F)
jan <- unlist(jan) ; jan[1500:2000]
# for some reason, the below order does not remove non-alphabet/한글 data compeletely. After this step, dataset still contains some numbers
jan
jan <- str_replace_all(jan, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
t_gsub
for (i in 1:length(t_gsub)) {
jan <- gsub(t_gsub[i], "", jan)
} ; head(jan, 400)
t_gsub <- readLines("응답소gsub.txt")
t_gsub
for (i in 1:length(t_gsub)) {
jan <- gsub(t_gsub[i], "", jan)
} ; head(jan, 400)
txt <- readLines("응답소_2015_01.txt")
jan <- sapply(txt, extractNoun, USE.NAMES = F)
jan <- unlist(jan) ; jan[1500:2000]
# for some reason, the below order does not remove non-alphabet/한글 data compeletely. After this step, dataset still contains some numbers
jan
jan <- str_replace_all(jan, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
t_gsub
for (i in 1:length(t_gsub)) {
jan <- gsub(t_gsub[i], "", jan)
}
jan <- gsub("\\W", "", jan)
jan <- gsub("\\d+", "", jan)
jan <- gsub("[:punct:]", "", jan)
jan <- gsub('[ㄱ-ㅎ]', "", jan)
jan <- gsub("(ㅜ|ㅠ)", "", jan)
jan <- gsub("을\\S*", "", jan)
head(jan, 100)
head(jan, 100:300)
jan[100:300]
jan[1:100]
jan <- gsub("까까\\S*", "", jan)
jan <- gsub("까\\S*", "", jan)
jan[1:100]
jan[400:600]
jan <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, jan )
txt <- readLines("응답소_2015_01.txt")
jan <- sapply(txt, extractNoun, USE.NAMES = F)
jan <- unlist(jan) ; jan[1500:2000]
# for some reason, the below order does not remove non-alphabet/한글 data compeletely. After this step, dataset still contains some numbers
jan
jan <- str_replace_all(jan, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
t_gsub
for (i in 1:length(t_gsub)) {
jan <- gsub(t_gsub[i], "", jan)
}
jan <- gsub("\\W", "", jan)
jan <- gsub("\\d+", "", jan)
jan <- gsub("[:punct:]", "", jan)
jan <- gsub('[ㄱ-ㅎ]', "", jan)
jan <- gsub("(ㅜ|ㅠ)", "", jan)
jan <- gsub("을\\S*", "", jan)
jan <- gsub("까\\S*", "", jan)
jan <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, jan )
jan[400:600]
write(unlist(jan), "Jan15_rev.txt")
rev <- read.table("Jan15_rev.txt")
nrow(rev)
count <- table(rev)
palete <- brewer.pal(5, "Set1")
par(bg="black")
wordcloud(names(count), freq = count, scale = c(2.5,0.4),
rot.per=0.35, min.freq=2, max.words=300,
random.order=F, random.color=T, colors=palete)
count <- table(rev)
count <- table(rev) ; table
count <- table(rev) ; count
jan <- gsub("기부부\\S*", "", jan)
jan <- gsub("기부\\S*", "", jan)
jan <- gsub("되되\\S*", "", jan)
txt <- readLines("응답소_2015_01.txt")
jan <- sapply(txt, extractNoun, USE.NAMES = F)
jan <- unlist(jan) ; jan[1500:2000]
# for some reason, the below order does not remove non-alphabet/한글 data compeletely. After this step, dataset still contains some numbers
jan
jan <- str_replace_all(jan, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
t_gsub
for (i in 1:length(t_gsub)) {
jan <- gsub(t_gsub[i], "", jan)
}
jan <- gsub("\\W", "", jan)
jan <- gsub("\\d+", "", jan)
jan <- gsub("[:punct:]", "", jan)
jan <- gsub('[ㄱ-ㅎ]', "", jan)
jan <- gsub("(ㅜ|ㅠ)", "", jan)
jan <- gsub("을\\S*", "", jan)
jan <- gsub("까\\S*", "", jan)
jan <- gsub("기부\\S*", "기부", jan)
jan <- gsub("되되\\S*", "", jan)
jan <- gsub("당시\\S*", "", jan)
jan <- gsub("담배값\\S*", "담배값", jan)
jan <- gsub("깍\\S*", "깍이다", jan)
jan <- gsub("관련\\S*", "", jan)
jan <- gsub("감동\\S*", "감동함", jan)
jan <- gsub("감사\\S*", "감사함", jan)
jan <- gsub("갖\\S*", "", jan)
jan <- gsub("건의\\S*", "건의", jan)
jan <- gsub("것\\S*", "", jan)
jan <- gsub("그래서\\S*", "", jan)
jan <- gsub("그런\\S*", "", jan)
jan <- gsub("년\\S*", "", jan)
jan <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, jan )
jan[400:600]
jan <- gsub("를\\S*", "", jan)
jan <- gsub("에\\S*", "", jan)
jan <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, jan )
jan[400:600]
write(unlist(jan), "Jan15_rev.txt")
rev <- read.table("Jan15_rev.txt")
nrow(rev)
count <- table(rev) ; count
wordcloud(names(count), freq = count, scale = c(5,0.4),
rot.per=0.35, min.freq=2, max.words=500,
random.order=F, random.color=T, colors=palete)
wordcloud(names(count), freq = count, scale = c(5,0.4),
rot.per=0.75, min.freq=2, max.words=500,
random.order=F, random.color=T, colors=palete)
wordcloud(names(count), freq = count, scale = c(5,0.4),
rot.per=0.35, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
wordcloud(names(count), freq = count, scale = c(4,0.4),
rot.per=0.35, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
palete <- brewer.pal(9, "Set1")
par(bg="black")
wordcloud(names(count), freq = count, scale = c(4,0.4),
rot.per=0.35, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
txt <- readLines("응답소_2015_01.txt")
jan <- sapply(txt, extractNoun, USE.NAMES = F)
jan <- unlist(jan) ; jan[1500:2000]
# for some reason, the below order does not remove non-alphabet/한글 data compeletely. After this step, dataset still contains some numbers
jan <- str_replace_all(jan, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
wordcloud(names(count), freq = count, scale = c(4,0.4),
rot.per=0.35, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
wordcloud(names(count), freq = count, scale = c(5,0.5),
rot.per=0.35, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
jan <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, jan )
jan[400:600]
write(unlist(jan), "Jan15_rev.txt")
rev <- read.table("Jan15_rev.txt")
nrow(rev)
count <- table(rev) ; count
palete <- brewer.pal(9, "Set1")
par(bg="black")
wordcloud(names(count), freq = count, scale = c(5,0.5),
rot.per=0.35, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
jan <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, jan )
jan[400:600]
write(unlist(jan), "Jan15_rev.txt")
rev <- read.table("Jan15_rev.txt")
nrow(rev)
count <- table(rev) ; count
palete <- brewer.pal(9, "Set1")
par(bg="black")
wordcloud(names(count), freq = count, scale = c(5,0.5),
rot.per=0.35, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
par(bg="black")
wordcloud(names(count), freq = count, scale = c(4,0.5),
rot.per=0.35, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
wordcloud(names(count), freq = count, scale = c(4,0.5),
rot.per=0.35, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
txt <- readLines("응답소_2015_01.txt")
jan <- sapply(txt, extractNoun, USE.NAMES = F)
jan <- unlist(jan) ; jan[1500:2000]
# for some reason, the below order does not remove non-alphabet/한글 data compeletely. After this step, dataset still contains some numbers
jan <- str_replace_all(jan, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
for (i in 1:length(t_gsub)) {
jan <- gsub(t_gsub[i], "", jan)
}  # for loops doesn't work very well.. so did some more hands-on work
jan <- gsub("\\W", "", jan)
jan <- gsub("\\d+", "", jan)
jan <- gsub("[:punct:]", "", jan)
jan <- gsub('[ㄱ-ㅎ]', "", jan)
jan <- gsub("(ㅜ|ㅠ)", "", jan)
jan <- gsub("제목", "", jan)
jan <- gsub("답변", "", jan)
jan <- gsub("박원순\\S*", "", jan)
jan <- gsub("서울시\\S*", "", jan)
jan <- gsub("시장\\S*", "", jan)
jan <- gsub("을\\S*", "", jan)
jan <- gsub("까\\S*", "", jan)
jan <- gsub("기부\\S*", "기부", jan)
jan <- gsub("되되\\S*", "", jan)
jan <- gsub("당시\\S*", "", jan)
jan <- gsub("담배값\\S*", "담배값", jan)
jan <- gsub("깍\\S*", "깍이다", jan)
jan <- gsub("관련\\S*", "", jan)
jan <- gsub("감동\\S*", "감동함", jan)
jan <- gsub("감사\\S*", "감사함", jan)
jan <- gsub("갖\\S*", "", jan)
jan <- gsub("건의\\S*", "건의", jan)
jan <- gsub("것\\S*", "", jan)
jan <- gsub("그래서\\S*", "", jan)
jan <- gsub("그런\\S*", "", jan)
jan <- gsub("년\\S*", "", jan)
jan <- gsub("를\\S*", "", jan)
jan <- gsub("에\\S*", "", jan)
jan <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, jan)
jan [300:400]
test_sub <- readLines("test_sub.txt")
test_sub
testtest <- c("234", "2019-04-30", "ㅋㅋ", "zz", "안녕하세요", "시장님", "시장", "ㅠㅠ", "시장아저씨")
testtest <- c("234", "2019-04-30", "ㅋㅋ", "zz", "안녕하세요", "시장님", "시장", "ㅠㅠ", "시장아저씨", "...", "...안녕녕")
testtest <- gsub("안녕녕녕
testtest <- gsub("안녕녕", "", testtest)
testtest
testtest <- gsub("...안녕녕", "", testtest)
testtest
testtest <- gsub(test_sub[i], "", testtest)
for (i in 1: length(test_sub)) {
testtest <- gsub(test_sub[i], "", testtest)
} ; testtest
testtest
for (i in 1: length(test_sub)) {
testtest <- gsub(test_sub[i], "", testtest)
testtest
} ; testtest
test_sub[i]
test_sub <- readLines("test_sub.txt")
test_sub
testtest <- c("234", "2019-04-30", "ㅋㅋ", "zz", "안녕하세요", "시장님", "시장", "ㅠㅠ", "시장아저씨", "...", "...안녕녕")
testtest <- gsub("...안녕녕", "", testtest)
testtest
for (i in 1: length(test_sub)) {
test_sub[i]
testtest <- gsub(test_sub[i], "", testtest)
testtest
} ; testtest
txt2 <- readLines("응답소_2015_02.txt")
feb <- sapply(txt2, extractNoun, USE.NAMES = F)
feb <- unlist(feb)
# for some reason, the below order does not remove non-alphabet/한글 data compeletely. After this step, dataset still contains some numbers
feb <- str_replace_all(feb, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
txt2 <- readLines("응답소_2015_02.txt")
feb <- sapply(txt2, extractNoun, USE.NAMES = F)
feb <- unlist(feb) ; feb[1700:1800]  #testing a random portion of the dataset
# for some reason, the below order does not remove non-alphabet/한글 data compeletely. After this step, dataset still contains some numbers
feb <- str_replace_all(feb, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
for (i in 1:length(t_gsub)) {
jan <- gsub(t_gsub[i], "", jan)
}  # for loops doesn't work very well.. so did some more hands-on work
jan [1700:1800]
feb [1700:1800]
feb <- gsub(t_gsub[i], "", feb)
for (i in 1:length(t_gsub)) {
feb <- gsub(t_gsub[i], "", feb)
}  # for loops doesn't work very well.. so did some more hands-on work
feb [1700:1800]
test_sub <- readLines("test_sub.txt")
test_sub
tes <- "\\W", "[ㄱ-ㅎ]", "시장\\S*", "(ㅜ|ㅠ)"
tes <- c( "\\W", "[ㄱ-ㅎ]", "시장\\S*", "(ㅜ|ㅠ)")
for (i in 1:length(tes)) {
st <-c("")
testtest <- gsub(tes[i], "", testtest)
st <- c(st, tes[i], "&&", testtest)
}
tes <- c( "\\W", "[ㄱ-ㅎ]", "시장\\S*", "(ㅜ|ㅠ)")
testtest<- c("234", "2019-04-30", "ㅋㅋ", "zz", "안녕하세요", "시장님", "시장", "ㅠㅠ", "시장아저씨", "...", "...안녕녕")
for (i in 1:length(tes)) {
st <-c("")
testtest <- gsub(tes[i], "", testtest)
st <- c(st, tes[i], "&&", testtest)
}
tes <- c( "\\W", "[ㄱ-ㅎ]", "시장\\S*", "(ㅜ|ㅠ)")
testtest<- c("234", "2019-04-30", "ㅋㅋ", "zz", "안녕하세요", "시장님", "시장", "ㅠㅠ", "시장아저씨", "...", "...안녕녕")
for (i in 1:length(tes)) {
st <-c("")
testtest <- gsub(tes[i], "", testtest)
st <- c(st, tes[i], "&&", testtest)
print(st)
}
testtest
re_subtxt <- c(t_gsub, "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","박원순\\S*","서울시\\S*","시장\\S*","을\\S*",
"까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*")
txt2 <- readLines("응답소_2015_02.txt")
feb <- sapply(txt2, extractNoun, USE.NAMES = F)
feb <- unlist(feb) ; feb[1700:1800]  #testing a random portion of the dataset
# for some reason, the below order does not remove non-alphabet/한글 data compeletely. After this step, dataset still contains some numbers
feb <- str_replace_all(feb, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
#------------------------------------------------------------------------
#
# for (i in 1:length(t_gsub)) {
#   feb <- gsub(t_gsub[i], "", feb)
# }  # for loops doesn't work very well.. so did some more hands-on work
# feb [1700:1800]
re_subtxt <- c(t_gsub, "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","박원순\\S*","서울시\\S*","시장\\S*","을\\S*",
"까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*")
for (i in 1:length(re_subtxt)) {
feb <- gsub(res_subtxt[i], "", feb)
}  # for loops doesn't work very well.. so did some more hands-on work
feb [1600:1800]
re_subtxt
re_subtxt <- c( "안녕하세요", "상담내용","때","시장님", "공개일", "000드", "Q", "상담내용", "--" , "==", "^ㅎ^" , "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","박원순\\S*","서울시\\S*","시장\\S*","을\\S*",
"까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*")
re_subtxt
for (i in 1:length(re_subtxt)) {
feb <- gsub(res_subtxt[i], "", feb)
}  # for loops doesn't work very well.. so did some more hands-on work
feb [1600:1800]
feb <- gsub(re_subtxt[i], "", feb)
for (i in 1:length(re_subtxt)) {
feb <- gsub(re_subtxt[i], "", feb)
}  # for loops doesn't work very well.. so did some more hands-on work
feb [1600:1800]
re_subtxt <- c("t_gsub," "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","박원순\\S*","서울시\\S*","시장\\S*","을\\S*",
"까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*")
re_subtxt
for (i in 1:length(re_subtxt)) {
feb <- gsub(re_subtxt[i], "", feb)
}  # for loops doesn't work very well.. so did some more hands-on work
feb [1600:1800]
feb [100:400]
feb [1100:1200]
feb [700:800]
re_subtxt <- c("t_gsub," "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","박원순\\S*","서울시\\S*","시장\\S*","을\\S*",
"까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*"
"아니\\S*", "랑\\S*", "안녕\\S*", "입니다", "생각", "는\\S*")
re_subtxt
txt2 <- readLines("응답소_2015_02.txt")
feb <- sapply(txt2, extractNoun, USE.NAMES = F)
feb <- unlist(feb) ; feb[1700:1800]  #testing a random portion of the dataset
# for some reason, the below order does not remove non-alphabet/한글 data compeletely. After this step, dataset still contains some numbers
feb <- str_replace_all(feb, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
#------------------------------------------------------------------------
### 전처리 과정은 데이터 셋의 표본으로 100~+ 여개의 데이터를 3 번 정도 랜덤한 부분에서 뽑아낸 후 눈에 띄는 데이터들을 골라 알맞은 데이터로 gsub 하는 방식으로 이루어졌음
re_subtxt <- c("t_gsub," "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","박원순\\S*","서울시\\S*","시장\\S*","을\\S*",
"까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*"
"아니\\S*", "랑\\S*", "안녕\\S*", "입니다", "생각", "는\\S*")
for (i in 1:length(re_subtxt)) {
feb <- gsub(re_subtxt[i], "", feb)
}  # for loops doesn't work very well.. so did some more hands-on work
feb <- gsub("아니\\S*", "기부", feb)
feb <- gsub("담배값\\S*", "담배값", feb)
feb <- gsub("감동\\S*", "감동함", feb)
feb <- gsub("감사\\S*", "감사함", feb)
feb <- gsub("건의\\S*", "건의", feb)
jan <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, jan)
feb <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, feb)
for (i in 1:length(re_subtxt)) {
feb <- gsub(re_subtxt[i], "", feb)
}  # for loops doesn't work very well.. so did some more hands-on work
feb <- gsub("아니\\S*", "기부", feb)
feb <- gsub("담배값\\S*", "담배값", feb)
feb <- gsub("감동\\S*", "감동함", feb)
feb <- gsub("감사\\S*", "감사함", feb)
feb <- gsub("건의\\S*", "건의", feb)
feb <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, feb)
#------------------------------------------------------------------------
write(unlist(feb), "feb15_rev.txt")
rev2 <- read.table("feb15_rev.txt")
nrow(rev2)
count2 <- table(rev2)
palete <- brewer.pal(9, "Set1")
par(bg="black")
wordcloud(names(count2), freq = count2, scale = c(7,0.5),
rot.per=0.85, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
t_gsub <- readLines("응답소gsub.txt")
re_subtxt <- c("t_gsub," "\\W", "\\d+" ,"[:punct:]" ,"[ㄱ-ㅎ]" , "(ㅜ|ㅠ)", "제목", "답변" ,"박원순\\S*", "서울시\\S*","시장\\S*" , "을\\S*", "까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*", "아니\\S*", "랑\\S*", "안녕\\S*", "입니다", "생각", "는\\S*")
t_gsub <- readLines("응답소gsub.txt")
re_subtxt <- c("t_gsub" "\\W", "\\d+" ,"[:punct:]" ,"[ㄱ-ㅎ]" , "(ㅜ|ㅠ)", "제목", "답변" ,"박원순\\S*", "서울시\\S*","시장\\S*" , "을\\S*", "까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*", "아니\\S*", "랑\\S*", "안녕\\S*", "입니다", "생각", "는\\S*")
t_gsub <- readLines("응답소gsub.txt")
re_subtxt <- c("t_gsub" ,"\\W", "\\d+" ,"[:punct:]" ,"[ㄱ-ㅎ]" , "(ㅜ|ㅠ)", "제목", "답변" ,"박원순\\S*", "서울시\\S*","시장\\S*" , "을\\S*", "까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*", "아니\\S*", "랑\\S*", "안녕\\S*", "입니다", "생각", "는\\S*")
par(bg="black")
wordcloud(names(count2), freq = count2, scale = c(7,0.5),
rot.per=0.15, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
wordcloud(names(count2), freq = count2, scale = c(7,0.5),
rot.per=0.25, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
txt <- readLines("응답소_2015_01.txt")
rbind(txt, txt2)
txt <- unlist(readLines("응답소_2015_01.txt"))
txt <- unlist(readLines("응답소_2015_01.txt"))
txt2 <- unlist(readLines("응답소_2015_02.txt"))
rbind(txt, txt2)
c(txt, txt2)
total <- c(unlist(readLines("응답소_2015_01.txt")),
unlist(readLines("응답소_2015_02.txt")),
unlist(readLines("응답소_2015_03.txt")),
unlist(readLines("응답소_2015_04.txt")),
unlist(readLines("응답소_2015_05.txt")),
unlist(readLines("응답소_2015_06.txt")),
unlist(readLines("응답소_2015_07.txt")),
unlist(readLines("응답소_2015_08.txt")),
unlist(readLines("응답소_2015_09.txt")),
unlist(readLines("응답소_2015_10.txt")),
unlist(readLines("응답소_2015_11.txt")),
unlist(readLines("응답소_2015_12.txt")))
total <- str_replace_all(total, "[^:alpha:]]","")
library(dplyr)
library(KoNLP)
library(wordcloud)
library(stringr)
library(RColorBrewer)
useSejongDic()
total <- str_replace_all(total, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
re_subtxt <- c("t_gsub," "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","박원순\\S*","서울시\\S*","시장\\S*","을\\S*",
"까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*"
"아니\\S*", "랑\\S*", "안녕\\S*", "입니다", "생각", "는\\S*")
for (i in 1:length(re_subtxt)) {
total <- gsub(re_subtxt[i], "", total)
}  # for loops doesn't work very well.. so did some more hands-on work
total <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, total)
write(unlist(total), "tot15_rev.txt")
revT <- read.table("tot15_rev.txt")
nrow(revT)
countT <- table(revT)
palete <- brewer.pal(9, "Set1")
par(bg="black")
wordcloud(names(countT), freq = countT, scale = c(7,0.5),
rot.per=0.85, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
library(dplyr)
library(KoNLP)
library(wordcloud)
library(stringr)
library(RColorBrewer)
useSejongDic()
total <- c(unlist(readLines("응답소_2015_01.txt")),
unlist(readLines("응답소_2015_02.txt")),
unlist(readLines("응답소_2015_03.txt")),
unlist(readLines("응답소_2015_04.txt")),
unlist(readLines("응답소_2015_05.txt")),
unlist(readLines("응답소_2015_06.txt")),
unlist(readLines("응답소_2015_07.txt")),
unlist(readLines("응답소_2015_08.txt")),
unlist(readLines("응답소_2015_09.txt")),
unlist(readLines("응답소_2015_10.txt")),
unlist(readLines("응답소_2015_11.txt")),
unlist(readLines("응답소_2015_12.txt")))
total <- str_replace_all(total, "[^:alpha:]]","")
t_gsub <- readLines("응답소gsub.txt")
re_subtxt <- c("t_gsub", "\\W", "\\d+","[:punct:]",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","제목","답변","박원순\\S*","서울시\\S*","시장\\S*","을\\S*",
"까\\S*","되\\S*","당시\\S*","관련\\S*","에\\S*" ,"를\\S*","년\\S*","그런\\S*","그래서\\S*","것\\S*","갖\\S*"
"아니\\S*", "랑\\S*", "안녕\\S*", "입니다", "생각", "는\\S*")
for (i in 1:length(re_subtxt)) {
total <- gsub(re_subtxt[i], "", total)
}  # for loops doesn't work very well.. so did some more hands-on work
total <- Filter(function(x) {nchar(x) >=2 && nchar(x) <=5}, total)
write(unlist(total), "tot15_rev.txt")
revT <- read.table("tot15_rev.txt")
nrow(revT)
countT <- table(revT)
palete <- brewer.pal(9, "Set1")
par(bg="black")
wordcloud(names(countT), freq = countT, scale = c(7,0.5),
rot.per=0.85, min.freq=2, max.words=100,
random.order=F, random.color=T, colors=palete)
str(count)
count_sorted <- order(count, decreasing=T)
head(count_sorted, 10)
count_sorted
count_sorted$name
names(count_sorted)
